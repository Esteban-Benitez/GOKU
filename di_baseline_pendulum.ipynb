{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5cb6648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SCALE INSPECTION (raw) ===\n",
      "[train(raw)] min=0 max=0.00195309 mean=0.0002069 std=0.000546321\n",
      "[ test(raw)] min=0 max=0.00195309 mean=0.00020686 std=0.000546319\n",
      "[Zero | raw] mean=0.207 ×10^3, std=0.003, sem=0.000\n",
      "[Saved DI | raw] mean=0.208 ×10^3, std=0.003, sem=0.000\n",
      "=== SCALE INSPECTION ([0,1] approx) ===\n",
      "[train([0,1])] min=0 max=1 mean=0.105934 std=0.279721\n",
      "[ test([0,1])] min=0 max=1 mean=0.105914 std=0.27972\n",
      "[Zero | ~[0,1]] mean=105.9 ×10^3, std=1.4, sem=0.0\n",
      "[Saved DI | ~[0,1]] mean=106.3 ×10^3, std=1.4, sem=0.0\n",
      "=== CALIBRATED TO PAPER ZERO BASELINE ===\n",
      "[Zero | calib]     mean=147.0 ×10^3 (target 147.0), std=2.0, sem=0.0\n",
      "[Saved DI | calib] mean=147.6 ×10^3, std=2.0, sem=0.0\n",
      "[Recomputed g(Z) | calib+sigmoid] mean=438.5 ×10^3, std=17.8, sem=0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Paths (edit) ---\n",
    "DATA_PATH       = \"data/pendulum/processed_data.pkl\"  # dict with 'train' and 'test' as numpy arrays [S,T,28,28]\n",
    "PRED_X_TEST     = \"checkpoints/pixel_pendulum/di/di_baseline_x_test.pkl\"     # [S,T,28,28]\n",
    "Z_TEST_PATH     = \"checkpoints/pixel_pendulum/di/di_baseline_z_test.pkl\"     # [S,T,2]\n",
    "G_STATE_PATH    = \"checkpoints/pixel_pendulum/di/di_baseline_generative.pkl\" # 2->784 MLP state_dict\n",
    "EXTRAP_MASK_PATH = None  # optional mask [S,T] of booleans for extrapolation-only evaluation\n",
    "\n",
    "H, W = 28, 28\n",
    "PAPER_ZERO_L1_X1E3 = 147.0  # target zero-baseline mean L1 ×10³ from the paper (pixel pendulum)\n",
    "\n",
    "def to_torch_img5d(np_arr):\n",
    "    \"\"\"Convert [S,T,H,W] numpy to torch [S,T,1,H,W] float32.\"\"\"\n",
    "    x = torch.from_numpy(np_arr).float()\n",
    "    assert x.dim() == 4 and x.shape[2] == H and x.shape[3] == W, f\"Expected [S,T,{H},{W}], got {tuple(x.shape)}\"\n",
    "    return x.unsqueeze(2)\n",
    "\n",
    "def per_frame_mae(xh, xg, mask=None):\n",
    "    \"\"\"xh, xg: [S,T,1,H,W] -> returns [S*T_masked] per-frame MAE.\"\"\"\n",
    "    diff = (xh - xg).abs().view(xg.shape[0], xg.shape[1], -1).mean(dim=2)  # [S,T]\n",
    "    if mask is not None:\n",
    "        diff = diff[mask]\n",
    "    return diff.reshape(-1)\n",
    "\n",
    "def summarize_x1e3(vals):\n",
    "    \"\"\"Return (mean, std, sem) × 1000 for paper-style reporting.\"\"\"\n",
    "    n = vals.numel()\n",
    "    mean = vals.mean().item()\n",
    "    std  = vals.std(unbiased=True).item() if n > 1 else 0.0\n",
    "    sem  = (std / (n ** 0.5)) if n > 1 else 0.0\n",
    "    return 1000.0 * mean, 1000.0 * std, 1000.0 * sem\n",
    "\n",
    "def print_stats(name, x):\n",
    "    print(f\"[{name}] min={x.min().item():.6g} max={x.max().item():.6g} mean={x.mean().item():.6g} std={x.std(unbiased=True).item():.6g}\")\n",
    "\n",
    "# --- Load data ---\n",
    "data = torch.load(DATA_PATH, weights_only=False)\n",
    "X_train_np = data[\"train\"]  # numpy [S_train,T_train,28,28]\n",
    "X_test_np  = data[\"test\"]   # numpy [S_test,T_test,28,28]\n",
    "\n",
    "X_train = to_torch_img5d(X_train_np)  # [S,T,1,28,28]\n",
    "X_test  = to_torch_img5d(X_test_np)   # [S,T,1,28,28]\n",
    "S, T = X_test.shape[:2]\n",
    "\n",
    "mask = None\n",
    "if EXTRAP_MASK_PATH and os.path.isfile(EXTRAP_MASK_PATH):\n",
    "    m = torch.load(EXTRAP_MASK_PATH, weights_only=False)\n",
    "    if isinstance(m, np.ndarray):\n",
    "        m = torch.from_numpy(m.astype(np.bool_))\n",
    "    assert m.shape == (S, T), f\"Mask must be [S,T], got {tuple(m.shape)}\"\n",
    "    mask = m.bool()\n",
    "\n",
    "# --- Inspect raw scale ---\n",
    "print(\"=== SCALE INSPECTION (raw) ===\")\n",
    "print_stats(\"train(raw)\", X_train)\n",
    "print_stats(\" test(raw)\", X_test)\n",
    "\n",
    "# --- Compute zero baseline in raw scale ---\n",
    "zero = torch.zeros_like(X_test)\n",
    "mae_zero_raw = per_frame_mae(zero, X_test, mask=mask)\n",
    "z_mean_raw, z_std_raw, z_sem_raw = summarize_x1e3(mae_zero_raw)\n",
    "print(f\"[Zero | raw] mean={z_mean_raw:.3f} ×10^3, std={z_std_raw:.3f}, sem={z_sem_raw:.3f}\")\n",
    "\n",
    "# --- Evaluate saved DI preds in raw scale ---\n",
    "X_hat_saved = torch.load(PRED_X_TEST, weights_only=False)  # [S,T,28,28]\n",
    "X_hat_saved = X_hat_saved.unsqueeze(2)  # -> [S,T,1,28,28]\n",
    "mae_saved_raw = per_frame_mae(X_hat_saved, X_test, mask=mask)\n",
    "s_mean_raw, s_std_raw, s_sem_raw = summarize_x1e3(mae_saved_raw)\n",
    "print(f\"[Saved DI | raw] mean={s_mean_raw:.3f} ×10^3, std={s_std_raw:.3f}, sem={s_sem_raw:.3f}\")\n",
    "\n",
    "# --- Approximate rescale to [0,1] using TRAIN data (min-max or max-only) ---\n",
    "# If pixels are already 0/1, this will have little effect. If they're tiny, it lifts them.\n",
    "train_min = X_train.min().item()\n",
    "train_max = X_train.max().item()\n",
    "if train_max > train_min:\n",
    "    # min-max to [0,1]\n",
    "    X_train_01 = (X_train - train_min) / (train_max - train_min)\n",
    "    X_test_01  = (X_test  - train_min) / (train_max - train_min)\n",
    "    X_hat_01   = (X_hat_saved - train_min) / (train_max - train_min)\n",
    "else:\n",
    "    # fallback: max-only scale\n",
    "    scale = train_max if train_max > 0 else 1.0\n",
    "    X_train_01 = X_train / scale\n",
    "    X_test_01  = X_test  / scale\n",
    "    X_hat_01   = X_hat_saved / scale\n",
    "\n",
    "print(\"=== SCALE INSPECTION ([0,1] approx) ===\")\n",
    "print_stats(\"train([0,1])\", X_train_01)\n",
    "print_stats(\" test([0,1])\", X_test_01)\n",
    "\n",
    "mae_zero_01  = per_frame_mae(torch.zeros_like(X_test_01), X_test_01, mask=mask)\n",
    "mae_saved_01 = per_frame_mae(X_hat_01, X_test_01, mask=mask)\n",
    "z_mean_01, z_std_01, z_sem_01 = summarize_x1e3(mae_zero_01)\n",
    "s_mean_01, s_std_01, s_sem_01 = summarize_x1e3(mae_saved_01)\n",
    "print(f\"[Zero | ~[0,1]] mean={z_mean_01:.1f} ×10^3, std={z_std_01:.1f}, sem={z_sem_01:.1f}\")\n",
    "print(f\"[Saved DI | ~[0,1]] mean={s_mean_01:.1f} ×10^3, std={s_std_01:.1f}, sem={s_sem_01:.1f}\")\n",
    "\n",
    "# --- Calibrate scale to match paper's zero baseline (linear rescale) ---\n",
    "# We want: mean_L1_zero_calibrated ≈ 147 ×10³.\n",
    "calib_factor = (PAPER_ZERO_L1_X1E3 / z_mean_raw) if z_mean_raw > 0 else 1.0\n",
    "X_test_cal  = X_test * calib_factor\n",
    "X_hat_cal   = X_hat_saved * calib_factor\n",
    "\n",
    "mae_zero_cal  = per_frame_mae(torch.zeros_like(X_test_cal), X_test_cal, mask=mask)\n",
    "mae_saved_cal = per_frame_mae(X_hat_cal, X_test_cal, mask=mask)\n",
    "z_mean_cal, z_std_cal, z_sem_cal = summarize_x1e3(mae_zero_cal)\n",
    "s_mean_cal, s_std_cal, s_sem_cal = summarize_x1e3(mae_saved_cal)\n",
    "print(\"=== CALIBRATED TO PAPER ZERO BASELINE ===\")\n",
    "print(f\"[Zero | calib]     mean={z_mean_cal:.1f} ×10^3 (target {PAPER_ZERO_L1_X1E3}), std={z_std_cal:.1f}, sem={z_sem_cal:.1f}\")\n",
    "print(f\"[Saved DI | calib] mean={s_mean_cal:.1f} ×10^3, std={s_std_cal:.1f}, sem={s_sem_cal:.1f}\")\n",
    "\n",
    "# --- Recompute g(Z) with bounded output (sigmoid), then evaluate in calibrated scale ---\n",
    "state = torch.load(G_STATE_PATH, weights_only=False)\n",
    "latent_dim = state['first_layer.weight'].shape[1]\n",
    "h1         = state['first_layer.weight'].shape[0]\n",
    "h2         = state['second_layer.weight'].shape[0]\n",
    "h3         = state['third_layer.weight'].shape[0]\n",
    "x_dim      = state['fourth_layer.weight'].shape[0]\n",
    "assert latent_dim == 2 and x_dim == H * W\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self, d, x, h1,h2,h3):\n",
    "        super().__init__()\n",
    "        self.first_layer  = nn.Linear(d, h1)\n",
    "        self.second_layer = nn.Linear(h1, h2)\n",
    "        self.third_layer  = nn.Linear(h2, h3)\n",
    "        self.fourth_layer = nn.Linear(h3, x)\n",
    "        self.act = nn.ReLU()\n",
    "        self.out_act = nn.Sigmoid()  # bound outputs to [0,1] for images\n",
    "    def forward(self, z):\n",
    "        x = self.act(self.first_layer(z))\n",
    "        x = self.act(self.second_layer(x))\n",
    "        x = self.act(self.third_layer(x))\n",
    "        x = self.fourth_layer(x)\n",
    "        return self.out_act(x)\n",
    "\n",
    "g = G(latent_dim, x_dim, h1,h2,h3).eval()\n",
    "missing, unexpected = g.load_state_dict(state, strict=True)\n",
    "if missing or unexpected:\n",
    "    raise RuntimeError(f\"State load mismatch: missing={missing}, unexpected={unexpected}\")\n",
    "\n",
    "Z_test = torch.load(Z_TEST_PATH, weights_only=False)  # [S,T,2]\n",
    "Z_flat = Z_test.reshape(S*T, latent_dim)\n",
    "with torch.no_grad():\n",
    "    X_hat_flat_sig = g(Z_flat)                     # [S*T,784] in [0,1]\n",
    "    X_hat_img_sig  = X_hat_flat_sig.view(S, T, 1, H, W)\n",
    "\n",
    "# Evaluate recomputed in calibrated scale (multiply by same factor)\n",
    "X_gt_cal_sig   = X_test * calib_factor\n",
    "X_hat_cal_sig  = X_hat_img_sig * calib_factor\n",
    "mae_re_cal     = per_frame_mae(X_hat_cal_sig, X_gt_cal_sig, mask=mask)\n",
    "r_mean_cal, r_std_cal, r_sem_cal = summarize_x1e3(mae_re_cal)\n",
    "print(f\"[Recomputed g(Z) | calib+sigmoid] mean={r_mean_cal:.1f} ×10^3, std={r_std_cal:.1f}, sem={r_sem_cal:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196bff0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GOKU (3.13.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
