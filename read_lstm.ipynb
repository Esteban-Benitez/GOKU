{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17ada844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* Classic Notebook */\n",
       ".output_wrapper, .output, .output_area {\n",
       "    max-height: 800px !important;\n",
       "}\n",
       ".output_scroll {\n",
       "    height: auto !important;\n",
       "    max-height: 800px !important;\n",
       "    overflow: auto !important;\n",
       "}\n",
       "\n",
       "/* JupyterLab */\n",
       ".jp-OutputArea-output {\n",
       "    max-height: none !important;\n",
       "    overflow: visible !important;\n",
       "}\n",
       ".jp-OutputArea-output .jp-RenderedText {\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       "\n",
       "/* Tracebacks / error boxes */\n",
       "div.traceback, .jp-OutputArea-output .jp-Error, .error {\n",
       "    max-height: 800px !important;\n",
       "    overflow: auto !important;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from icecream import ic\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "style = \"\"\"\n",
    "<style>\n",
    "/* Classic Notebook */\n",
    ".output_wrapper, .output, .output_area {\n",
    "    max-height: 800px !important;\n",
    "}\n",
    ".output_scroll {\n",
    "    height: auto !important;\n",
    "    max-height: 800px !important;\n",
    "    overflow: auto !important;\n",
    "}\n",
    "\n",
    "/* JupyterLab */\n",
    ".jp-OutputArea-output {\n",
    "    max-height: none !important;\n",
    "    overflow: visible !important;\n",
    "}\n",
    ".jp-OutputArea-output .jp-RenderedText {\n",
    "    white-space: pre-wrap;\n",
    "}\n",
    "\n",
    "/* Tracebacks / error boxes */\n",
    "div.traceback, .jp-OutputArea-output .jp-Error, .error {\n",
    "    max-height: 800px !important;\n",
    "    overflow: auto !important;\n",
    "    white-space: pre-wrap;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "display(HTML(style))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc3b1e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['args', 'model', 'opt', 'data_args'])\n",
      "dict_keys(['train', 'test'])\n",
      "(450, 100, 28, 28)\n",
      "(50, 100, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'pendulum'\n",
    "# model_name = 'cvs' # no opt\n",
    "# model_name='double_pendulum' # no opt\n",
    "model_name = 'pendulum_friction'\n",
    "\n",
    "model_name2=\"lstm\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with open(f'checkpoints/{model_name}/{model_name2}_model.pkl', 'rb') as f:\n",
    "    ckpt = torch.load(f, weights_only=False)\n",
    "with open(f'data/{model_name}/processed_data.pkl', 'rb') as processed_data_file:\n",
    "    x = torch.load(processed_data_file, weights_only=False)\n",
    "test_data = x['test']\n",
    "train_data = x['train']\n",
    "args = ckpt['args']   # saved argparse.Namespace\n",
    "model_state = ckpt['model']\n",
    "data_args = ckpt.get('data_args', None)\n",
    "print(ckpt.keys())\n",
    "print(x.keys())\n",
    "# --- build model and load weights ---\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "assert 'opt' in list(ckpt.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808aa486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f20a616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendulum_friction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mdata_args\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m{\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mmask_rate\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m0.01\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mmodel\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mpendulum\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mnoise_std\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m0.0\u001b[39m\u001b[38;5;245m}\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mask_rate': 0.01, 'noise_std': 0.0, 'model': 'pendulum'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_name)\n",
    "with open(f'data/{model_name}/data_args.pkl', 'rb') as data_args:\n",
    "    data_args = torch.load(data_args, weights_only=False)\n",
    "ic(data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b92ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendulum_friction\n",
      "(input_dim=[28, 28], hidden_dim=16, num_layers=2)\n",
      "defaults: {'input_dim': [28, 28], 'hidden_dim': 16, 'num_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "if model_name == \"pendulum\":\n",
    "    from models.LSTM import create_lstm_pendulum as the_goku_model\n",
    "    import models.LSTM as specific_goku_model\n",
    "\n",
    "\n",
    "elif model_name == \"pendulum_friction\":\n",
    "    from models.LSTM import create_lstm_pendulum_friction as the_goku_model\n",
    "elif model_name == \"cvs\":\n",
    "    from models.LSTM import create_lstm_cvs as the_goku_model\n",
    "elif model_name == \"double_pendulum\":\n",
    "    print(\"HELLLO\")\n",
    "    from models.LSTM import create_lstm_double_pendulum as the_goku_model\n",
    "else:\n",
    "    raise Exception(\"NO MODEL SELECTED\")\n",
    "print(model_name)\n",
    "sig = inspect.signature(the_goku_model)\n",
    "print(sig)\n",
    "# parameter defaults (including kw-only)\n",
    "spec = inspect.getfullargspec(the_goku_model)\n",
    "defaults = {}\n",
    "if spec.defaults:\n",
    "    defaults.update({name: val for name, val in zip(spec.args[-len(spec.defaults):], spec.defaults)})\n",
    "if spec.kwonlydefaults:\n",
    "    defaults.update(spec.kwonlydefaults)\n",
    "print(\"defaults:\", defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f775a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b463c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goku = the_goku_model()\n",
    "optimizer = torch.optim.Adam(goku.parameters(), lr=1e-3) # change to whatever optimizer was used\n",
    "goku.load_state_dict(model_state)\n",
    "optimizer.load_state_dict(ckpt['opt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ca12ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.shape, true.shape: torch.Size([50, 28, 28]) torch.Size([50, 100, 28, 28]) device: cuda:0 cuda:0\n",
      "Aligning time dimension: slicing to 28 timesteps (pred 28, true 100)\n",
      "Expanded pred H->HxW by repeating across W\n",
      "Mean MAE: 0.42544726 Mean RMSE: 0.42823845\n"
     ]
    }
   ],
   "source": [
    "# python\n",
    "# make sure names and device match\n",
    "goku = goku.to(device)                  # your model instance\n",
    "\n",
    "\n",
    "goku.eval()\n",
    "x = torch.as_tensor(test_data).float().to(device)   # (N,T,...) or (T,N,...)\n",
    "\n",
    "# time array (use saved args if available)\n",
    "delta_t = getattr(args, 'delta_t', 1.0)\n",
    "seq_len = x.shape[1]\n",
    "t = torch.arange(0.0, seq_len * float(delta_t), step=float(delta_t), device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = goku(x)\n",
    "    pred = out[0] if isinstance(out, tuple) else out\n",
    "\n",
    "# undo normalization if data_args present (zscore or minmax)\n",
    "def undo_norm(z, data_args):\n",
    "    if not data_args: return z\n",
    "    norm = data_args.get('norm', None)\n",
    "    if norm == 'zscore' and 'x_mean' in data_args and 'x_std' in data_args:\n",
    "        mean = torch.as_tensor(data_args['x_mean'], device=z.device).view(1,1,-1)\n",
    "        std  = torch.as_tensor(data_args['x_std'], device=z.device).view(1,1,-1)\n",
    "        return z * std + mean\n",
    "    if norm in ('zero_to_one','minmax') and 'x_min' in data_args and 'x_max' in data_args:\n",
    "        mn = torch.as_tensor(data_args['x_min'], device=z.device).view(1,1,-1)\n",
    "        mx = torch.as_tensor(data_args['x_max'], device=z.device).view(1,1,-1)\n",
    "        return z * (mx - mn) + mn\n",
    "    return z\n",
    "\n",
    "pred = undo_norm(pred, data_args)\n",
    "true = undo_norm(x, data_args)\n",
    "\n",
    "# compute per-timestep MAE / RMSE (average over all axes except time)\n",
    "# Now compute error using robust alignment logic\n",
    "import numpy as _np\n",
    "\n",
    "print(\"pred.shape, true.shape:\", pred.shape, true.shape, \"device:\", pred.device, true.device)\n",
    "\n",
    "# If model returned (T, N, ...) transpose to (N, T, ...)\n",
    "if pred.shape[0] != true.shape[0] and pred.shape[1] == true.shape[0]:\n",
    "    perm = [1, 0] + list(range(2, pred.ndim))\n",
    "    pred = pred.permute(*perm).contiguous()\n",
    "    print(\"Permuted pred ->\", pred.shape)\n",
    "\n",
    "# batch dim check\n",
    "if pred.shape[0] != true.shape[0]:\n",
    "    raise RuntimeError(f\"Batch size mismatch: pred {pred.shape[0]} vs true {true.shape[0]}\")\n",
    "\n",
    "# Align time length by slicing to min time (do this before subtraction)\n",
    "min_time = min(pred.shape[1], true.shape[1])\n",
    "if pred.shape[1] != true.shape[1]:\n",
    "    print(f\"Aligning time dimension: slicing to {min_time} timesteps (pred {pred.shape[1]}, true {true.shape[1]})\")\n",
    "    pred = pred[:, :min_time].contiguous()\n",
    "    true = true[:, :min_time].contiguous()\n",
    "\n",
    "# helper to match feature shapes (attempt reshape/broadcast)\n",
    "def reconcile_feature_shapes(pred, true):\n",
    "    pred_feat = tuple(pred.shape[2:])\n",
    "    true_feat = tuple(true.shape[2:])\n",
    "    if pred_feat == true_feat:\n",
    "        return pred, true\n",
    "    pred_prod = int(_np.prod(pred_feat)) if len(pred_feat) else 1\n",
    "    true_prod = int(_np.prod(true_feat)) if len(true_feat) else 1\n",
    "\n",
    "    # Case A: pred flattened (single dim equal to product of true feature dims)\n",
    "    if len(pred_feat) == 1 and pred_prod == true_prod:\n",
    "        new_shape = (pred.shape[0], pred.shape[1]) + true_feat\n",
    "        try:\n",
    "            pred = pred.view(*new_shape)\n",
    "            print(f\"Reshaped pred features {pred_feat} -> {true_feat}\")\n",
    "            return pred, true\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Case B: pred is scalar/channel (broadcast across true)\n",
    "    if pred_prod == 1:\n",
    "        pred = pred.view(pred.shape[0], pred.shape[1], *([1] * len(true_feat)))\n",
    "        pred = pred.expand(-1, -1, *true_feat)\n",
    "        print(\"Broadcasted scalar/single-channel pred ->\", true_feat)\n",
    "        return pred, true\n",
    "\n",
    "    # Case C: pred has 1 spatial dimension and true has 2, try expand if dims match\n",
    "    if len(pred_feat) == 1 and len(true_feat) == 2:\n",
    "        p0 = pred_feat[0]\n",
    "        h, w = true_feat\n",
    "        if p0 == h:\n",
    "            pred = pred.unsqueeze(-1).expand(-1, -1, h, w)\n",
    "            print(\"Expanded pred H->HxW by repeating across W\")\n",
    "            return pred, true\n",
    "        if p0 == w:\n",
    "            pred = pred.unsqueeze(-2).expand(-1, -1, h, w)\n",
    "            print(\"Expanded pred W->HxW by repeating across H\")\n",
    "            return pred, true\n",
    "\n",
    "    # Case D: pred has same number of feature dims but unequal sizes -> try broadcasting if feasible\n",
    "    if len(pred_feat) == len(true_feat):\n",
    "        can_broadcast = all(p == t or p == 1 for p, t in zip(pred_feat, true_feat))\n",
    "        if can_broadcast:\n",
    "            expand_sizes = [t if p == 1 else p for p, t in zip(pred_feat, true_feat)]\n",
    "            pred = pred.view(pred.shape[0], pred.shape[1], *pred_feat)\n",
    "            pred = pred.expand(-1, -1, *expand_sizes)\n",
    "            print(\"Broadcasted pred features ->\", true_feat)\n",
    "            return pred, true\n",
    "\n",
    "    # Unfixable mismatch\n",
    "    print(\"Cannot reconcile feature shapes automatically.\")\n",
    "    print(f\"pred feature shape: {pred_feat} (prod={pred_prod}), true feature shape: {true_feat} (prod={true_prod})\")\n",
    "    raise RuntimeError(\n",
    "        \"Feature shape mismatch: pred {} vs true {}. \"\n",
    "        \"If this is expected, add a reshape/broadcast rule; otherwise modify model/data to return matching shapes.\".format(pred_feat, true_feat)\n",
    "    )\n",
    "\n",
    "pred, true = reconcile_feature_shapes(pred, true)\n",
    "\n",
    "time_dim = 1\n",
    "reduce_dims = tuple(i for i in range(pred.ndim) if i != time_dim)\n",
    "\n",
    "# compute error AFTER aligning time and reconciling features\n",
    "err = pred - true\n",
    "mae_per_t = err.abs().mean(dim=reduce_dims).cpu().numpy()\n",
    "rmse_per_t = err.pow(2).mean(dim=reduce_dims).sqrt().cpu().numpy()\n",
    "print(\"Mean MAE:\", mae_per_t.mean(), \"Mean RMSE:\", rmse_per_t.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eec0051f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae_per_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmae_per_t\u001b[49m.shape)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(mae_per_t.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'mae_per_t' is not defined"
     ]
    }
   ],
   "source": [
    "print(mae_per_t.shape)\n",
    "print(mae_per_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bd05bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mae_per_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m time = np.arange(\u001b[32m100\u001b[39m)\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m6\u001b[39m,\u001b[32m3\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m plt.plot(time, \u001b[43mmae_per_t\u001b[49m, label=\u001b[33m'\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m plt.plot(time, rmse_per_t, label=\u001b[33m'\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m); plt.ylabel(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m); plt.legend(); plt.grid(\u001b[38;5;28;01mTrue\u001b[39;00m); plt.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'mae_per_t' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "time = np.arange(100)\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(time, mae_per_t, label='MAE')\n",
    "plt.plot(time, rmse_per_t, label='RMSE')\n",
    "plt.xlabel('time'); plt.ylabel('error'); plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a66e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa36c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GOKU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
